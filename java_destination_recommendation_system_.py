# -*- coding: utf-8 -*-
"""Java_Destination_Recommendation_System_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r_CoXJcr-n9iLJcXyVRD0ef2GNRYQbqA

# Import Library
"""

# Melakukan import library-library yang dibutuhkan
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from zipfile import ZipFile
import tensorflow as tf
import gdown
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

"""# Load Data"""

# Proses Load Data
url = 'https://drive.google.com/uc?export=download&id=1c6mBIjThJdQ4G6rhafCCnQr77iP6wNub'

gdown.download(url,'data.zip',quiet = False)

# Mengekstrak seluruh data pada data.zip
with ZipFile('data.zip','r') as zip:
  zip.extractall()

# Mencetak jumlah data setiap file csv
package = pd.read_csv('/content/package_tourism.csv')
rating = pd.read_csv('/content/tourism_rating.csv')
destination = pd.read_csv('/content/tourism_with_id.csv')
user = pd.read_csv('/content/user.csv')

print("Jumlah package destinasi yang ditawarkan:",len(package.Package.unique()))
print("Jumlah rating yang diberikan:",len(rating.User_Id))
print("Jumlah destinasi yang ditawarkan:",len(destination.Place_Id.unique()))
print("Jumlah pengguna :",len(user.User_Id.unique()))

"""# Exploratory Data Analysis (EDA)

## Data Understanding

Pada dataset ini terdiri dari 4 file yaitu sebagai berikut:
- package : merupakan paket-paket destinasi tempat wisata yang ditawarkan dari dari berbagai kota
- rating : merupakan rating yang diberikan user terhadap destinasi tempat wisata
- destination : merupakan destinasi tempat-tempat wisata di 5 kota besar di Indonesia (Jakarta, Bandung, Semarang, Surabaya, Yogyakarta)
- user : merupakan pengguna yang melakukan rating

Variabel rating, destination, dan user akan digunakan pada model rekomendasi. Sedangkan, variabel package hanya untuk melihat data dengan perspektif dalam bentuk paket perjalanan.

### Destination variable
"""

# Mencetak informasi destination
destination.info()

# Mencetak beberapa data pada destination
destination.head()

# Dari informasi dan tampilan data diatas, terdapat 2 kolom yang tidak relevan
# Melakukan drop pada kolom 'Unnamed: 11', dan 'Unnamed: 12'

destination = destination.drop(columns=['Unnamed: 11','Unnamed: 12'], axis=1)

# Melakukan pengecekan terhadap kolom missing values
destination.isnull().sum()

# Dikarenakan data yang kosong hampir setengah dari keseluruhan data pada kolom time_minutes
# Maka tidak akan dilakukan drop pada data tersebut, namun imputasi dengan nilai mean

destination['Time_Minutes'] = destination['Time_Minutes'].fillna(destination['Time_Minutes'].mean().round(1))

# Mencetak beberapa data pada destination kembali
destination.head()

# Mengecek missing value kembali
destination.isnull().sum()

# # Melihat jumlah destinasi yang ditawarkan berdasarkan setiap kota
# destination.groupby('City').Place_Name.count()

"""### User Variable"""

# Mencetak informasi user
user.info()

# Mencetak beberapa data pada user
user.head()

"""### Rating Variable"""

# Mencetak informasi rating
rating.info()

# Mencetak beberapa data pada rating
rating.head()

# Mencetak deskripsi statistik pada data rating
rating.describe()

"""Kolom-kolom rating antara lain:

- User_Id, merupakan identitas pengguna.
- Place_Id, merupakan identitas destinasi tempat wisata.
- Place_Ratings, merupakan data rating untuk destinasi tempat wisata.

Dari data diatas juga didapatkan bahwa rating pada destinasi tempat wisata memiliki rentang 1-5

## Univariate dan Multivariate Analysis
"""

# Visualisasi destination yang ditawarkan berdasarkan kategorinya
plt.figure(figsize=(10,5))
sns.countplot(x='Category',data=destination, palette='Set2', hue='Category')
plt.xlabel('Kategori Destinasi')
plt.ylabel('Jumlah Destinasi')
plt.title('Jumlah Destinasi Berdasarkan Kategori')
plt.show()

# Visualisasi destination yang ditawarkan berdasarkan setiap kota
plt.figure(figsize=(10,5))
sns.countplot(x='City',data=destination, palette='Set2', hue='City')
plt.xlabel('Kota')
plt.ylabel('Jumlah Destinasi')
plt.title('Jumlah Destinasi Berdasarkan Kota')
plt.show()

# Visualisasi destination dengan rating tertinggi (10 data)
top_ten_destination = destination.sort_values(by='Rating', ascending=False).head(10)

plt.figure(figsize=(10,5))
sns.barplot(x='Rating', y='Place_Name',data=top_ten_destination, palette='Set2', hue='Place_Name')
plt.xlabel('Rating')
plt.ylabel('Nama Destinasi Wisata')
plt.title('Destinasi Wisata dengan Rating Tertinggi')
plt.show()

# Visualisasi asal daerah pengguna
asal_daerah_user = user['Location'].apply(lambda x: x.split(',')[1])

plt.figure(figsize=(10,5))
sns.countplot(y=asal_daerah_user, palette='Set2', hue=asal_daerah_user)
plt.xlabel('Jumlah pengguna')
plt.ylabel('Asal daerah pengguna')
plt.title('Distribusi pengguna berdasarkan asal daerahnya')
plt.show()

# Visualisasi distribusi umur pengguna
plt.figure(figsize=(10, 5))
plt.hist(user['Age'], bins=20, color='#fc8d62')
plt.xlabel('Umur Pengguna')
plt.ylabel('Jumlah Pengguna')
plt.title('Distribusi Umur dari pengguna')
plt.show()

"""# Data Preprocessing

### Mengetahui Jumlah Rating Destinasi
"""

# Menggabungkan dataframe rating dengan destinasi berdasarkan nilai Place_Id
rating_destination = pd.merge(rating, destination, on='Place_Id', how='left')
rating_destination

# Cek missing value dengan fungsi isnull()
rating_destination.isnull().sum()

# Menghitung jumlah rating dan jumlah pengguna melakukan rating pada destinasi
rating_destination.groupby('Place_Id').agg({'Place_Ratings':'sum', 'Place_Name':'count'})

"""### Menggabungkan data rating dengan fitur nama destinasi, kategori, kota, harga, lama kunjungan, dan rating tempat"""

# Definisikan dataframe rating ke dalam variabel all_destination_rate
all_destination_rate = rating
all_destination_rate

# Menggabungkan semua fitur yang dibutuhkan kedalam dataframe all_destination_rate
all_destination = pd.merge(all_destination_rate, destination[['Place_Id','Price','Time_Minutes','Rating','Category','City','Place_Name']], on='Place_Id', how='left')
all_destination

"""# Data Preparation"""

# Mengecek missing value pada dataframe all_destination
all_destination.isnull().sum()

"""### Pengecekan fitur-fitur kategorikal"""

# Mengurutkan destinasi berdasarkan Place_Id kemudian memasukkannya ke dalam variabel fix_destinasi
fix_destination = all_destination.sort_values('Place_Id', ascending=True)
fix_destination

# Mengecek berapa jumlah fix_destinastion
len(fix_destination.Place_Id.unique())

# Mengecek kategori 'Category' yang unik
fix_destination.Category.unique()

# Mengubah nilai category dengan penulisan Snake Case
fix_destination['Category'] = fix_destination['Category'].str.replace(' ','_')
fix_destination.Category.unique()

# Mengecek kategori 'City' yang unik
fix_destination.City.unique()

"""Dari pengecekan diatas, tidak terdapat kategori yang aneh dan pada analisis setiap fitur sebelumnya di EDA tidak ada kategori yang memiliki nilai yang sedikit sehingga Data telah bersih

# Model Development

### Melakukan Konsolidasi Data
"""

# Melakukan groupping dengan 'Place_Id' dan rata-rata Place_Ratings setiap Place_Id
consolidated_destination = fix_destination.groupby('Place_Id').agg({
    'Place_Ratings':'mean',  # jumlah rating yang dilakukan setiap pengguna
    'Price':'first',  # harga sama setiap Place_id
    'Time_Minutes':'first',  # lama kunjungan sama setiap Place_id
    'Rating':'first',  # rating sama setiap Place_id
    'Category':'first',  # kategori sama setiap Place_id
    'City':'first',  # kota sama setiap Place_id
    'Place_Name':'first',  # nama destinasi sama setiap Place_id
}).reset_index()
consolidated_destination

# Menggabungkan fitur category dan city lalu drop kedua fitur tersebut
consolidated_destination['Category_City'] = consolidated_destination['Category'] + '_' + consolidated_destination['City']
consolidated_destination = consolidated_destination.drop(columns=['Category','City'])
consolidated_destination

"""### Mengkonversi fitur-fitur kedalam list"""

# Mengonversi data series ‘Place_Id’ menjadi dalam bentuk list
destination_id = consolidated_destination['Place_Id'].tolist()

# Mengonversi data series ‘Place_Name’ menjadi dalam bentuk list
destination_name = consolidated_destination['Place_Name'].tolist()

# Mengonversi data series ‘Category_City’ menjadi dalam bentuk list
destination_category_city = consolidated_destination['Category_City'].tolist()

# Mengonversi data series ‘Price’ menjadi dalam bentuk list
destination_price = consolidated_destination['Price'].tolist()

# Mengonversi data series ‘Time_Minutes’ menjadi dalam bentuk list
destination_tm = consolidated_destination['Time_Minutes'].tolist()

# Mengonversi data series ‘Rating’ menjadi dalam bentuk list
destination_rating = consolidated_destination['Rating'].tolist()

print(len(destination_id))
print(len(destination_name))
print(len(destination_category_city))
print(len(destination_price))
print(len(destination_tm))
print(len(destination_rating))

# Membuat dictionary destination
destination_new = pd.DataFrame({
    'id': destination_id,
    'name': destination_name,
    'category_city': destination_category_city,
    'price': destination_price,
    'time_minutes': destination_tm,
    'rating': destination_rating
})
destination_new

"""## Content-Based Filtering"""

data = destination_new
data.sample(5)

"""### TF-IDF Vectorizer fitur Categorical"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data category, city
tf.fit(data['category_city'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['category_city'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""### Standarisasi fitur Numerical"""

from sklearn.preprocessing import StandardScaler

# Inisialisasi StandardScaler
scaler = StandardScaler()

# Melakukan standarisasi pada data price, time_minutes, dan rating
data_numeric = data[['price','time_minutes','rating']]
scaler.fit(data_numeric)
data_numeric = scaler.transform(data_numeric)
data_numeric = pd.DataFrame(data_numeric, columns=['price','time_minutes','rating'])
data_numeric.head()

"""### Penggabungan fitur"""

from scipy.sparse import csr_matrix, hstack

# Gabungkan fitur kategorikal dengan fitur numerik
numeric_features_sparse = csr_matrix(data_numeric)
categoric_features = tfidf_matrix
combined_features = hstack([categoric_features, numeric_features_sparse])

combined_features

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada combined features
cosine_sim = cosine_similarity(combined_features)
cosine_sim

"""### Mendapatkan Rekomendasi

contoh Pengguna X pernah mengunjungi Monumen Nasional. Kemudian, saat pengguna tersebut berencana untuk Mengunjungi tempat wisata lain, sistem akan merekomendasikan ... . Nah, rekomendasi tempat wisata inilah berdasarkan kesamaan yang dihitung dengan cosine similarity pada tahap sebelumnya.
"""

def recommend_items(place_name, data = data, similarity_matrix = cosine_sim, k=3):
    """
    Memberikan rekomendasi tempat wisata berdasarkan kemiripan item (cosine similarity).

    Parameter:
    ---
    place_name : tipe data string (str)
                Nama tempat wisata yang akan dicari rekomendasinya.
    data : tipe data pd.DataFrame (object)
           DataFrame yang berisi informasi tentang tempat wisata, dengan kolom 'place_name' yang mencakup nama-nama tempat wisata.
    similarity_matrix : tipe data numpy.ndarray (object)
                        Matriks kesamaan antara item, di mana nilai-nilai menunjukkan seberapa mirip dua item satu sama lain.
    k : tipe data integer (int)
            Jumlah rekomendasi teratas yang akan dikembalikan.
    ---

    Fungsi ini mencari indeks dari tempat wisata yang sesuai dengan nama tempat (`place_name`) dalam DataFrame `data`.
    Kemudian, fungsi ini menggunakan matriks kesamaan (`similarity_matrix`) untuk menemukan item-item yang paling mirip
    dengan item tersebut, berdasarkan nilai kesamaan tertinggi. Rekomendasi yang diberikan adalah nama-nama tempat yang
    memiliki kesamaan tertinggi, mengabaikan tempat yang sama dengan `place_name` itu sendiri.

    Langkah-langkah:
    1. Menentukan indeks baris dari tempat wisata yang sesuai dengan `place_name`.
    2. Menghitung indeks dari item yang paling mirip menggunakan matriks kesamaan.
    3. Mengembalikan nama-nama tempat yang paling mirip dengan `place_name`, kecuali tempat itu sendiri.
    """

    # Menentukan indeks baris dari tempat yang sesuai dengan place_name
    place_index = data[data['name'] == place_name].index[0]

    # Menghitung indeks item yang paling mirip
    similar_indices = similarity_matrix[place_index].argsort()[-k-1:][::-1]

    # Menyimpan Data destinasi tempat yang mirip
    similar_items = data.iloc[similar_indices]

    # Drop place_name agar nama destinasi yang dicari tidak muncul dalam daftar rekomendasi
    similar_items = similar_items[similar_items['name'] != place_name]

    # Mengembalikan nama tempat yang direkomendasikan
    return similar_items.head(k)

# Dalam kasus ini, nanti kita akan mencari destinasi wisata yang mirip dengan Monumen Nasional
data[data.name.eq('Monumen Nasional')]

# Mendapatkan rekomendasi destinasi wisata yang mirip dengan Monumen Nasional
recommend_items('Monumen Nasional')

"""Dari rekomendasi diatas didapatkan 3 rekomendasi destinasi wisata yang mirip dengan Monumen Nasional yaitu Monumen Selamat Datang, Museum Tekstil, dan Museum Sasmita Loka Ahmad Yani

## Collaborative Filtering (User Based)
"""

data = rating.copy()
data.sample(5)

# Mengubah User_Id menjadi list tanpa nilai yang sama
user_ids = data['User_Id'].unique().tolist()
print('list User_Id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke User_Id: ', user_encoded_to_user)

# Mengubah Place_Id menjadi list tanpa nilai yang sama
destination_ids = data['Place_Id'].unique().tolist()

# Melakukan proses encoding Place_Id
destination_to_destination_encoded = {x: i for i, x in enumerate(destination_ids)}

# Melakukan proses encoding angka ke Place_Id
destination_encoded_to_destination = {i: x for i, x in enumerate(destination_ids)}

print('list Place_Id: ', destination_ids)
print('encoded Place_Id: ', destination_to_destination_encoded)
print('encoded angka ke Place_Id: ', destination_encoded_to_destination)

# Mapping User_Id ke dataframe user
data['user'] = data['User_Id'].map(user_to_user_encoded)

# Mapping Place_Id ke dataframe destinasi
data['destination'] = data['Place_Id'].map(destination_to_destination_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah destinasi
num_destination = len(destination_to_destination_encoded)
print(num_destination)

# Mengubah rating menjadi nilai float
data['Place_Ratings'] = data['Place_Ratings'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(data['Place_Ratings'])

# Nilai maksimal rating
max_rating = max(data['Place_Ratings'])

print('Number of User: {}, Number of Destination: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_destination, min_rating, max_rating
))

"""### Membagi Dataset menjadi Train dan Validation"""

# Mengacak dataset
df = data.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan destinasi menjadi satu value (x)
x = df[['user', 'destination']].values

# Membuat variabel y untuk membuat rating dari hasil (y)
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### Proses Training dan Rekomendasi"""

# Membuat Kelas RecommenderNet
class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_destination, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_destination = num_destination
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.destination_embedding = layers.Embedding( # layer embeddings destination
        num_destination,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.destination_bias = layers.Embedding(num_destination, 1) # layer embedding destination bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    destination_vector = self.destination_embedding(inputs[:, 1]) # memanggil layer embedding 3
    destination_bias = self.destination_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_destination = tf.tensordot(user_vector, destination_vector, 2)

    x = dot_user_destination + user_bias + destination_bias

    return tf.nn.sigmoid(x) # activation sigmoid

# inisialisasi model
model = RecommenderNet(num_users, num_destination, 50)

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# inisialisasi callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_root_mean_squared_error')<0.3):
      print('nilai validasi RMSE dibawah 0.3')
      self.model.stop_training = True

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks = [myCallback()]
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

destination_df = destination_new
df = rating.copy()

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
destination_visited_by_user = df[df.User_Id == user_id]

# Mengambil destinasi yang belum pernah dikunjungi
destination_not_visited = destination_df[~destination_df['id'].isin(destination_visited_by_user.Place_Id.values)]['id']
destination_not_visited = list(
    set(destination_not_visited)
    .intersection(set(destination_to_destination_encoded.keys()))
)

# Mengubah ke dalam bentuk array
destination_not_visited = [[destination_to_destination_encoded.get(x)] for x in destination_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_destination_array = np.hstack(
    ([[user_encoder]] * len(destination_not_visited), destination_not_visited)
)

# Mendapatkan rekomendasi
ratings = model.predict(user_destination_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_destination_ids = [
    destination_encoded_to_destination.get(destination_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Destination with high ratings from user')
print('----' * 8)

top_destination_user = (
    destination_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)

destination_df_rows = destination_df[destination_df['id'].isin(top_destination_user)]
for row in destination_df_rows.itertuples():
    print(row.name, ':', row.category_city)

print('----' * 8)
print('Top 10 destination recommendation')
print('----' * 8)

recommended_destination = destination_df[destination_df['id'].isin(recommended_destination_ids)]
for row in recommended_destination.itertuples():
    print(row.name, ':', row.category_city)